import json
import sys
import logging
from typing import Dict

# Configure logging
logging.basicConfig(level=logging.INFO, format="%(levelname)s: %(message)s")


def calculate_total_time(parameters: Dict[str, float]) -> float:


    size_in_queries = parameters["size_in_queries"]
    bandwidth_ext_IO = parameters["bandwidth_ext_IO"]

    # Execution time on the host system
    T_bucketizing = parameters["T_bucketizing"] 
    T_sorting = parameters["T_sorting"] 

    # Size of the output generated by preparing-input-queries/
    size_pruned_queries = parameters["size_pruned_queries"]  

    # Size of the k-mer database 
    size_database = parameters["size_database"]

    # Size of the output generated by finding-candidate-species/intersection-finding.cpp
    size_intersection = parameters["size_intersection"]

    # Size of the taxID database
    size_taxID_database = parameters["size_taxID_database"]

    # Based on the bandwidth reported by MQSim for sequential reads from all channels
    # i.e., number_of_channels * channel_bandwidth
    bandwidth_internal = parameters["bandwidth_internal"]

    bandwidth_internal_DRAM = parameters["bandwidth_internal_DRAM"]

    # Accelerator throughput is calculated via the synthesis of the Verilog implementation in hdl/
    T_accelerator_intersection = parameters["T_accelerator_intersection"]
    T_accelerator_taxID = parameters["T_accelerator_taxID"]

    # Execution time on the host system
    T_fetching_species = parameters["T_fetching_species"]



    T_IO_in_queries = size_in_queries / bandwidth_ext_IO
    T_IO_transfer_queries = size_pruned_queries / bandwidth_ext_IO

    # Intersection finding times
    T_flash_access_intersection = size_database / bandwidth_internal
    T_DRAM_access_intersection = (size_pruned_queries + size_intersection) / bandwidth_internal_DRAM
    T_intersection_finding = max(
        T_flash_access_intersection,
        T_DRAM_access_intersection,
        T_accelerator_intersection,
    )

    # TaxID retrieval times
    T_flash_access_taxID = size_taxID_database / bandwidth_internal
    T_DRAM_access_taxID = (size_pruned_queries + size_intersection) / bandwidth_internal_DRAM
    T_taxID_retrieval = max(
        T_flash_access_taxID,
        T_DRAM_access_taxID,
        T_accelerator_taxID,
    ) + T_fetching_species

    # Total time
    T_total = max(T_IO_in_queries, T_bucketizing) + max(
        T_sorting + T_IO_transfer_queries, T_intersection_finding
    ) + T_taxID_retrieval

    return T_total


def load_config(config_file: str) -> Dict[str, float]:
    """
    Load the configuration file.

    Args:
        config_file (str): Path to the JSON configuration file.

    Returns:
        dict: Configuration data as a dictionary.
    """
    with open(config_file, "r") as file:
        return json.load(file)


def main():

    if len(sys.argv) < 2:
        logging.error("Usage: python code.py <config_file>")
        sys.exit(1)

    config_file = sys.argv[1]

    try:
        # Load the configuration
        config = load_config(config_file)

        # Calculate total time
        total_time = calculate_total_time(config)

        # Output the result
        logging.info(f"Total Time: {total_time}")

    except FileNotFoundError:
        logging.error(f"The configuration file '{config_file}' was not found.")
    except KeyError as e:
        logging.error(f"Missing key in configuration file: {e}")
    except json.JSONDecodeError:
        logging.error(f"Failed to decode JSON in the configuration file.")


if __name__ == "__main__":
    main()
